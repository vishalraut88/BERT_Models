{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEz21BXxaSBlPW2X1rpU1s",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vishalraut88/BERT_Models/blob/main/BERT_disaster_Tweet_or_not.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4aoqwG0UiOYo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --depth 1 -b v2.3.0 https://github.com/tensorflow/models.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DrDSPqX4iLyO",
        "outputId": "adc19246-de39-4b74-c3d2-836284fa7644"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'models'...\n",
            "remote: Enumerating objects: 2650, done.\u001b[K\n",
            "remote: Counting objects: 100% (2650/2650), done.\u001b[K\n",
            "remote: Compressing objects: 100% (2311/2311), done.\u001b[K\n",
            "remote: Total 2650 (delta 505), reused 1389 (delta 306), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (2650/2650), 34.02 MiB | 26.90 MiB/s, done.\n",
            "Resolving deltas: 100% (505/505), done.\n",
            "Note: switching to '400d68abbccda2f0f6609e3a924467718b144233'.\n",
            "\n",
            "You are in 'detached HEAD' state. You can look around, make experimental\n",
            "changes and commit them, and you can discard any commits you make in this\n",
            "state without impacting any branches by switching back to a branch.\n",
            "\n",
            "If you want to create a new branch to retain commits you create, you may\n",
            "do so (now or later) by using -c with the switch command. Example:\n",
            "\n",
            "  git switch -c <new-branch-name>\n",
            "\n",
            "Or undo this operation with:\n",
            "\n",
            "  git switch -\n",
            "\n",
            "Turn off this advice by setting config variable advice.detachedHead to false\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# install requirements to use tensorflow/models repository\n",
        "!pip install -Uqr models/official/requirements.txt\n",
        "# you may have to restart the runtime afterwards"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mt-mkoariQtW",
        "outputId": "c8c331f1-db40-4d78-fc22-2f555fc746bf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m50.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m215.1/215.1 KB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/12.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.2/280.2 KB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m238.9/238.9 KB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m43.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 KB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m68.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.2/9.2 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m79.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 KB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m965.4/965.4 KB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.9.0 requires jedi>=0.10, which is not installed.\n",
            "numba 0.56.4 requires numpy<1.24,>=1.18, but you have numpy 1.24.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "sNA50m3nVFWq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import sys\n",
        "sys.path.append('models')\n",
        "from official.nlp.data import classifier_data_lib\n",
        "from official.nlp.bert import tokenization\n",
        "from official.nlp import optimization\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv(\"train.csv\")\n",
        "test_data = pd.read_csv(\"test.csv\")"
      ],
      "metadata": {
        "id": "n1v8jwasXx7l"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data.target.value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPlx3bYusfAn",
        "outputId": "db4770d4-9a5f-4c65-a354-2cb7426cf5ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    4342\n",
              "1    3271\n",
              "Name: target, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df,remaining =train_test_split(train_data,random_state=42,test_size=0.2,stratify=train_data.target.values) \n",
        "valid_df,test_df=train_test_split(remaining,random_state=42,test_size=0.5,stratify=remaining.target.values)"
      ],
      "metadata": {
        "id": "0-4dJ-Efscj6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "McQrav51ukFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 1 : Convert input data(/frame) to tensor slices"
      ],
      "metadata": {
        "id": "qo7JpZeuuo85"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_data = tf.data.Dataset.from_tensor_slices((train_df.text.values,train_df.target.values))\n",
        "tf_test_data = tf.data.Dataset.from_tensor_slices((valid_df.text.values,valid_df.target.values))"
      ],
      "metadata": {
        "id": "6gs8OsgQnGlI"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for text,label in tf_train_data.take(5):\n",
        "  print(text)\n",
        "  print(label)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OjmvIGRKuL4E",
        "outputId": "f623690f-b9af-4040-e28e-5bc5b1e8ada9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(b'Sassy city girl country hunk stranded in Smoky Mountain snowstorm #AoMS http://t.co/nkKcTttsD9 #ibooklove #bookboost', shape=(), dtype=string)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n",
            "tf.Tensor(b\"God's Kingdom (Heavenly Gov't) will rule over all people on the earth after Armageddon.  http://t.co/8HGcBXUkz0  http://t.co/4kopkCyvTt\", shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b'Mopheme and Bigstar Johnson are a problem in this game body bagging niggas #VuzuHustle', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b'@VixMeldrew sounds like a whirlwind life!', shape=(), dtype=string)\n",
            "tf.Tensor(0, shape=(), dtype=int64)\n",
            "tf.Tensor(b'Malaysia confirms plane debris washed up on Reunion Island is from Flight MH370 http://t.co/YS3WALzvjg', shape=(), dtype=string)\n",
            "tf.Tensor(1, shape=(), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 2 : Import bert layer and instantiate tokenizer object\n"
      ],
      "metadata": {
        "id": "rcnhYhmOv6O5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_layer = hub.KerasLayer('https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/2',trainable=True)\n",
        "label_list=[0,1]\n",
        "max_seq_length = 128\n",
        "train_batch_size=32"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qpGOEcWnu0Eh",
        "outputId": "188f4f0d-0f99-4e68-8b17-dd45e2fe0ba9"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Please fix your imports. Module tensorflow.python.training.tracking.data_structures has been moved to tensorflow.python.trackable.data_structures. The old module will be deleted in version 2.11.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_file = bert_layer.resolved_object.vocab_file.asset_path.numpy()\n",
        "do_lower_case = bert_layer.resolved_object.do_lower_case.numpy()\n",
        "tokenizer = tokenization.FullTokenizer(vocab_file=vocab_file,do_lower_case=do_lower_case)\n",
        "# tokens = tokenizer.wordpiece_tokenizer.tokenize(\"hi,How are you \")\n",
        "# tokenizer.convert_tokens_to_ids(tokens)"
      ],
      "metadata": {
        "id": "fxnF7B7Qwt48"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3 : Bert preprocessing \n",
        "1. InputExamples\n",
        "2. Map function"
      ],
      "metadata": {
        "id": "92hkeNxH2zpr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example=classifier_data_lib.InputExample(\n",
        "                                  guid=None,\n",
        "                                  text_a=\"hi,how are you\",\n",
        "                                  text_b=None,\n",
        "                                  label=1\n",
        "                                  )\n",
        "features = classifier_data_lib.convert_single_example(0,example,label_list,max_seq_length,tokenizer)\n",
        "print(features.input_ids)\n",
        "print(features.input_mask)\n",
        "print(features.segment_ids)\n",
        "print(features.label_id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g5Fl2xI04xM4",
        "outputId": "5c57a3ae-8880-4340-c2f3-15a9ba75d324"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[101, 7632, 1010, 2129, 2024, 2017, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_features(text,tokenizer,ip_label,label_list,max_seq_length):\n",
        "  example = classifier_data_lib.InputExample(guid=None,text_a=text,text_b=None,label=ip_label)\n",
        "  features = classifier_data_lib.convert_single_example(0,example,label_list,max_seq_length,tokenizer)\n",
        "  return (features.input_ids,features.input_mask,features.segment_ids,features.label_id)\n",
        "  "
      ],
      "metadata": {
        "id": "dvgcmx0h1FJ6"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You want to use [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) to apply this function to each element of the dataset. [`Dataset.map`](https://www.tensorflow.org/api_docs/python/tf/data/Dataset#map) runs in graph mode.\n",
        "\n",
        "- Graph tensors do not have a value.\n",
        "- In graph mode you can only use TensorFlow Ops and functions.\n",
        "\n",
        "So you can't `.map` this function directly: You need to wrap it in a [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function). The [`tf.py_function`](https://www.tensorflow.org/api_docs/python/tf/py_function) will pass regular tensors (with a value and a `.numpy()` method to access it), to the wrapped python function."
      ],
      "metadata": {
        "id": "25N9Pbcz9yVu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Step 3 : Wrap the get features function in pytorcj"
      ],
      "metadata": {
        "id": "gTWLNnNK9iZ8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow._api.v2.compat.v1 import py_function\n",
        "def get_features_map(text,label):\n",
        "  input_ids,mask_ids,segment_ids,label_id=tf.py_function(get_features,inp=[text,label],Tout=[tf.int32,tf.int32,tf.int32,tf.int32])\n",
        "  #### Shape of the output tensor is not implicitly set by wrapper function\n",
        "  #### so we have to manually set the shape.\n",
        "  input_ids.set_shape([max_seq_length])\n",
        "  mask_ids.set_shape([max_seq_length])\n",
        "  segment_ids.set_shape([max_seq_length])\n",
        "\n",
        "  label_id.set_shape([])\n",
        "  features_dict= {'input_word_ids':input_ids,\n",
        "                  'input_mask':mask_ids,\n",
        "                  'input_type_ids':segment_ids\n",
        "                  }\n",
        "\n",
        "  return (features_dict,label_id)\n",
        "  \n",
        "\n"
      ],
      "metadata": {
        "id": "b1Cp87xG8nmN"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf_train_data = (tf_train_data.map(get_features_map,\n",
        "                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                  .shuffle(1000)\n",
        "                  .batch(32,drop_remainder=True)\n",
        "                  .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")\n",
        "\n",
        "\n",
        "tf_test_data = (tf_test_data.map(get_features_map,\n",
        "                  num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "                  .shuffle(1000)\n",
        "                  .batch(32,drop_remainder=True)\n",
        "                  .prefetch(tf.data.experimental.AUTOTUNE)\n",
        ")"
      ],
      "metadata": {
        "id": "TcuwnUJxIFa0"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train data spec\n",
        "tf_train_data.element_spec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGb8gK8UH9BM",
        "outputId": "139edad5-fc28-4ce4-c092-f2fc4cd181dc"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "({'input_word_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_mask': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None),\n",
              "  'input_type_ids': TensorSpec(shape=(32, 128), dtype=tf.int32, name=None)},\n",
              " TensorSpec(shape=(32,), dtype=tf.int32, name=None))"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PnwBqdQBJ3wI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}